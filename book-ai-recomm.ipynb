{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Book recommendation system","metadata":{}},{"cell_type":"markdown","source":"## Imports & set up","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers torch sentence-transformers gradio requests beautifulsoup4 langchain langchain-community\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:08:17.306538Z","iopub.execute_input":"2025-12-29T18:08:17.307276Z","iopub.status.idle":"2025-12-29T18:08:21.067769Z","shell.execute_reply.started":"2025-12-29T18:08:17.307241Z","shell.execute_reply":"2025-12-29T18:08:21.066945Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip install -q bitsandbytes accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:08:21.069307Z","iopub.execute_input":"2025-12-29T18:08:21.069625Z","iopub.status.idle":"2025-12-29T18:08:24.357363Z","shell.execute_reply.started":"2025-12-29T18:08:21.069592Z","shell.execute_reply":"2025-12-29T18:08:24.356584Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install -q plotly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:08:24.358439Z","iopub.execute_input":"2025-12-29T18:08:24.358771Z","iopub.status.idle":"2025-12-29T18:08:27.505341Z","shell.execute_reply.started":"2025-12-29T18:08:24.358730Z","shell.execute_reply":"2025-12-29T18:08:27.504562Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport requests\nimport pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nfrom bs4 import BeautifulSoup\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:08:27.507360Z","iopub.execute_input":"2025-12-29T18:08:27.507635Z","iopub.status.idle":"2025-12-29T18:08:27.513210Z","shell.execute_reply.started":"2025-12-29T18:08:27.507607Z","shell.execute_reply":"2025-12-29T18:08:27.512222Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## The Model Class","metadata":{}},{"cell_type":"code","source":"class OpenSourceLLM:\n    def __init__(self):\n        print(\"Real LLM loaded â€” ready to recommend like a human\")\n        self.api_key = \"your_key_here\n        self.api_url = \"https://api.groq.com/openai/v1/chat/completions\"\n        self.model = \"llama-3.3-70b-versatile\"  \n\n    def generate(self, prompt, max_tokens=200):\n        if not self.api_key:\n            return \"Sweet romance with amazing chemistry and all the feels!\"\n    \n        import requests\n        payload = {\n            \"model\": self.model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"max_tokens\": max_tokens,\n            \"temperature\": 0.8\n        }\n    \n        try:\n            response = requests.post(\n                self.api_url,\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key.strip()}\",  # Strip any spaces\n                    \"Content-Type\": \"application/json\"\n                },\n                json=payload,\n                timeout=30\n            )\n            print(f\"Groq status: {response.status_code}\")  # Debug line\n            if response.status_code == 200:\n                return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n            else:\n                print(f\"Groq error details: {response.text}\")  # Shows exact error\n                return \"Sweet romance with amazing chemistry and all the feels!\"\n        except Exception as e:\n            print(f\"Request failed: {e}\")\n            return \"Sweet romance with amazing chemistry and all the feels!\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:18.008030Z","iopub.execute_input":"2025-12-29T18:10:18.008330Z","iopub.status.idle":"2025-12-29T18:10:18.015284Z","shell.execute_reply.started":"2025-12-29T18:10:18.008300Z","shell.execute_reply":"2025-12-29T18:10:18.014566Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"llm = OpenSourceLLM()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:20.155203Z","iopub.execute_input":"2025-12-29T18:10:20.155830Z","iopub.status.idle":"2025-12-29T18:10:20.159808Z","shell.execute_reply.started":"2025-12-29T18:10:20.155797Z","shell.execute_reply":"2025-12-29T18:10:20.158988Z"}},"outputs":[{"name":"stdout","text":"Real LLM loaded â€” ready to recommend like a human\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Book Search Engine","metadata":{}},{"cell_type":"code","source":"\nclass BookSearchEngine:\n    \"\"\"Search books from multiple sources on the web\"\"\"\n    \n    def __init__(self):\n        self.google_books_url = \"https://www.googleapis.com/books/v1/volumes\"\n        self.openlibrary_url = \"https://openlibrary.org/search.json\"\n    \n    def search_google_books(self, query, max_results=10):\n        \"\"\"Search Google Books API\"\"\"\n        try:\n            params = {\n                'q': query,\n                'maxResults': max_results,\n                'printType': 'books',\n                'orderBy': 'relevance'\n            }\n            response = requests.get(self.google_books_url, params=params, timeout=10)\n            data = response.json()\n            \n            books = []\n            for item in data.get('items', []):\n                vol_info = item.get('volumeInfo', {})\n                books.append({\n                    'title': vol_info.get('title', 'Unknown'),\n                    'authors': ', '.join(vol_info.get('authors', ['Unknown'])),\n                    'description': vol_info.get('description', 'No description available'),\n                    'categories': ', '.join(vol_info.get('categories', ['General'])),\n                    'published': vol_info.get('publishedDate', 'N/A'),\n                    'rating': vol_info.get('averageRating', 'N/A'),\n                    'thumbnail': vol_info.get('imageLinks', {}).get('thumbnail', ''),\n                    'source': 'Google Books'\n                })\n            return books\n        except Exception as e:\n            print(f\"Google Books error: {e}\")\n            return []\n    \n    def search_openlibrary(self, query, max_results=10):\n        \"\"\"Search Open Library API\"\"\"\n        try:\n            params = {\n                'q': query,\n                'limit': max_results,\n                'fields': 'title,author_name,first_publish_year,subject,ratings_average'\n            }\n            response = requests.get(self.openlibrary_url, params=params, timeout=10)\n            data = response.json()\n            \n            books = []\n            for doc in data.get('docs', []):\n                books.append({\n                    'title': doc.get('title', 'Unknown'),\n                    'authors': ', '.join(doc.get('author_name', ['Unknown'])),\n                    'description': ', '.join(doc.get('subject', ['No description'])[:3]),\n                    'categories': ', '.join(doc.get('subject', ['General'])[:2]),\n                    'published': doc.get('first_publish_year', 'N/A'),\n                    'rating': doc.get('ratings_average', 'N/A'),\n                    'thumbnail': '',\n                    'source': 'Open Library'\n                })\n            return books\n        except Exception as e:\n            print(f\"Open Library error: {e}\")\n            return []\n    \n    def search_books(self, query, max_results=15):\n        \"\"\"Search books from multiple sources\"\"\"\n        print(f\"Searching for: {query}\")\n        \n        # Search both APIs\n        google_results = self.search_google_books(query, max_results=max_results//2)\n        openlibrary_results = self.search_openlibrary(query, max_results=max_results//2)\n        \n        # Combine results\n        all_books = google_results + openlibrary_results\n        \n        # Remove duplicates based on title similarity\n        unique_books = []\n        seen_titles = set()\n        for book in all_books:\n            title_lower = book['title'].lower()\n            if title_lower not in seen_titles:\n                seen_titles.add(title_lower)\n                unique_books.append(book)\n        \n        print(f\"Found {len(unique_books)} unique books\")\n        return unique_books\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:20.630893Z","iopub.execute_input":"2025-12-29T18:10:20.631570Z","iopub.status.idle":"2025-12-29T18:10:20.643340Z","shell.execute_reply.started":"2025-12-29T18:10:20.631538Z","shell.execute_reply":"2025-12-29T18:10:20.642519Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"search_engine = BookSearchEngine()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:20.827740Z","iopub.execute_input":"2025-12-29T18:10:20.827952Z","iopub.status.idle":"2025-12-29T18:10:20.831115Z","shell.execute_reply.started":"2025-12-29T18:10:20.827931Z","shell.execute_reply":"2025-12-29T18:10:20.830550Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Testing the search ","metadata":{}},{"cell_type":"code","source":"test_results = search_engine.search_books(\"science fiction space\", max_results=5)\nprint(f\"\\nTest search found {len(test_results)} books:\")\nfor book in test_results[:3]:\n    print(f\"- {book['title']} by {book['authors']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:21.276186Z","iopub.execute_input":"2025-12-29T18:10:21.276534Z","iopub.status.idle":"2025-12-29T18:10:22.497057Z","shell.execute_reply.started":"2025-12-29T18:10:21.276504Z","shell.execute_reply":"2025-12-29T18:10:22.496371Z"}},"outputs":[{"name":"stdout","text":"Searching for: science fiction space\nFound 4 unique books\n\nTest search found 4 books:\n- Deep Space; Eight Stories of Science Fiction by Robert Silverberg\n- Science Fiction and Space Futures by Eugene Morlock Emme\n- 2001 by Arthur C. Clarke\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Book Embeddings","metadata":{}},{"cell_type":"code","source":"\nprint(\"Loading embedding model...\")\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2')\nprint(\"Embedding model ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:22.498245Z","iopub.execute_input":"2025-12-29T18:10:22.498518Z","iopub.status.idle":"2025-12-29T18:10:25.339940Z","shell.execute_reply.started":"2025-12-29T18:10:22.498464Z","shell.execute_reply":"2025-12-29T18:10:25.339139Z"}},"outputs":[{"name":"stdout","text":"Loading embedding model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e98808aaa0643928dcc41ea7ba0a090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"892cb8e930cf4ff6858a5c5846ed69b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af540bd8d965454ba40602935aedbb1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21bba11fb76948b49604be66a40a5f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4770870e62b44567abb5654f03b1bcf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf8c313c8ce45aaae1de4a443703727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72cfa156189845048636fde5aebf76d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f4f228f68c4dada2031580055b5053"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded462f0c87e4765afbe3306e0af3b46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"444b4f22262849a487c7ef65e5e55618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5eb8c49d424c0682e25fab48ddb61f"}},"metadata":{}},{"name":"stdout","text":"Embedding model ready!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\ndef create_book_embeddings(books):\n    \"\"\"Create embeddings for book search results\"\"\"\n    if not books:\n        return np.array([])\n    \n    # Create rich text for embedding\n    texts = []\n    for book in books:\n        text = f\"{book['title']}. {book['description']} {book['categories']}\"\n        texts.append(text)\n    \n    embeddings = embedding_model.encode(texts)\n    return embeddings\n\ndef semantic_rerank(books, query, top_k=5):\n    \"\"\"Rerank books using semantic similarity\"\"\"\n    if not books:\n        return []\n    \n    book_embeddings = create_book_embeddings(books)\n    query_embedding = embedding_model.encode([query])\n    \n    similarities = cosine_similarity(query_embedding, book_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_k:][::-1]\n    \n    ranked_books = [books[i] for i in top_indices]\n    return ranked_books","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:25.340883Z","iopub.execute_input":"2025-12-29T18:10:25.341114Z","iopub.status.idle":"2025-12-29T18:10:25.348475Z","shell.execute_reply.started":"2025-12-29T18:10:25.341091Z","shell.execute_reply":"2025-12-29T18:10:25.347732Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## LLM Part ","metadata":{}},{"cell_type":"code","source":"class AIBookRecommender:\n    def __init__(self, llm, search_engine, embedding_model):\n        self.llm = llm\n        self.search_engine = search_engine\n        self.embedding_model = embedding_model\n        self.reading_list = []\n        self.last_search_results = []\n        self.last_embeddings = None\n\n    def create_book_embeddings(self, books):\n        \"\"\"Create embeddings for book search results\"\"\"\n        if not books:\n            return np.array([])\n        \n        texts = []\n        for book in books:\n            text = f\"{book['title']}. {book['description']} {book['categories']}\"\n            texts.append(text)\n        \n        embeddings = self.embedding_model.encode(texts)\n        return embeddings\n\n    def semantic_rerank(self, books, query, top_k=20):\n        \"\"\"Rerank books using semantic similarity\"\"\"\n        if not books:\n            return []\n        \n        book_embeddings = self.create_book_embeddings(books)\n        query_embedding = self.embedding_model.encode([query])\n        \n        similarities = cosine_similarity(query_embedding, book_embeddings)[0]\n        top_indices = np.argsort(similarities)[-top_k:][::-1]\n        \n        ranked_books = [books[i] for i in top_indices]\n        return ranked_books\n\n    def extract_intent(self, user_message):\n        \"\"\"Extract book title and tropes using LLM + fallbacks, then build smart search query\"\"\"\n        lower = user_message.lower()\n\n        # If no \"like\" or genre keywords â†’ just search for the message + \"books\"\n        if not any(phrase in lower for phrase in [\"like\", \"similar\", \"recommend\", \"loved\", \"read\", \"want\", \"something\"]):\n            return user_message + \" books\", None\n\n        # LLM prompt to extract structured intent\n        intent_prompt = f\"\"\"\nUser message: \"{user_message}\"\n\nExtract:\n1. The exact book title they want something similar to (if mentioned). Return \"None\" if not clear.\n2. List of key tropes, genres, or vibes they mentioned or implied (e.g. fake dating, enemies to lovers, dark academia, cozy fantasy, slow burn, found family).\n\nFormat exactly as:\nBOOK: <title or None>\nTROPES: trope1, trope2, trope3\n\nOnly respond with those two lines.\n\"\"\"\n\n        response = self.llm.generate(intent_prompt, max_tokens=100).strip()\n\n        # Parse LLM response\n        book_title = None\n        tropes = []\n        for line in response.split('\\n'):\n            if line.startswith(\"BOOK:\"):\n                title = line[5:].strip()\n                if title.lower() != \"none\":\n                    book_title = title\n            elif line.startswith(\"TROPES:\"):\n                trope_str = line[7:].strip()\n                if trope_str:\n                    tropes = [t.strip() for t in trope_str.split(',') if t.strip()]\n\n        # Fallback: regex for book title\n        if not book_title:\n            import re\n            match = re.search(r\"(?:like|similar to|loved|read|something like)\\s+([a-zA-Z0-9\\s,'\\\"\\-\\.&!]+?)(?:\\s+by|\\?|$|,)\", lower)\n            if match:\n                book_title = match.group(1).strip().title()\n\n        # Fallback: keyword trope detection\n        if not tropes:\n            common_checks = {\n                'fake dating': ['fake dat', 'fake relat', 'pretend', 'fake boyfriend', 'fake girlfriend'],\n                'friends to lovers': ['friend', 'best friend', 'childhood friend', 'friends to lovers'],\n                'enemies to lovers': ['enem', 'hate to love', 'rival'],\n                'grumpy sunshine': ['grumpy', 'sunshine'],\n                'slow burn': ['slow burn', 'slowburn'],\n                'romcom': ['romcom', 'romantic comedy', 'funny romance'],\n                'young adult': ['ya', 'young adult', 'teen'],\n                'new adult': ['new adult', 'college'],\n                'dark academia': ['dark academia', 'academic'],\n                'cozy fantasy': ['cozy', 'wholesome fantasy'],\n                'closed door': ['clean', 'closed door', 'no spice', 'sweet'],\n            }\n            for trope, keywords in common_checks.items():\n                if any(k in lower for k in keywords):\n                    tropes.append(trope)\n\n        # Build powerful search query\n        parts = []\n        if book_title:\n            parts.append(f'\"{book_title}\"')\n            parts.append(\"similar books\")\n            parts.append(\"read alikes\")\n            parts.append(\"goodreads recommendations\")\n            parts.append(\"booktok recommendations\")\n        else:\n            parts.append(\"books\")\n\n        if tropes:\n            parts.extend(tropes)\n\n        if \"book\" not in \" \".join(parts).lower():\n            parts.append(\"book\")\n\n        query = \" \".join(parts)\n        return query, book_title\n\n    def chat(self, user_message, history=[]):\n        user_message_lower = user_message.lower().strip()\n    \n        # Commands\n        if user_message_lower.startswith(\"add \"):\n            # your existing add logic\n            pass\n        elif user_message_lower in [\"reading list\", \"my list\"]:\n            # your existing reading list logic\n            pass\n        else:\n            # FULL LLM MODE â€” this is the magic\n            prompt = f\"\"\"\n    You are the world's best book recommender in 2025. You know every BookTok trend, Goodreads list, and reader preference.\n    \n    User wants: \"{user_message}\"\n    \n    Recommend exactly 5 books that REAL readers say are the closest matches.\n    Rules:\n    - If a specific book is mentioned â†’ prioritize same author + exact trope matches\n    - Always respect age group: YA for teens, adult for mature\n    - Use current trends: BookTok hits, popular 2024-2025 releases\n    - No children's books, textbooks, or random classics unless asked\n    \n    Format:\n    1. \"Title\" by Author\n       â†’ One sharp sentence why it's perfect\n    \n    Examples:\n    \"betting on you\" â†’ Lynn Painter books first (Better Than the Movies, The Do-Over, etc.)\n    \"the housemaid\" â†’ Freida McFadden thrillers (Never Lie, The Teacher, etc.)\n    \"love hypothesis\" â†’ Ali Hazelwood + Spanish Love Deception\n    \"\"\"\n    \n            recommendations = self.llm.generate(prompt, max_tokens=500).strip()\n    \n            # Optional: Fetch covers for visual polish (doesn't affect quality)\n            try:\n                cover_books = self.search_engine.search_books(user_message + \" book\", max_results=20)\n                ranked = self.semantic_rerank(cover_books, user_message, top_k=5)\n                self.last_search_results = ranked\n            except:\n                self.last_search_results = []\n    \n            response = f\"ðŸ“š **Perfect matches for: \\\"{user_message}\\\"**\\n\\n\"\n            response += recommendations + \"\\n\\n\"\n            if self.last_search_results:\n                response += \"ðŸ“– **With covers:**\\n\\n\"\n                for book in self.last_search_results[:3]:\n                    response += f\"**{book['title']}** by {book['authors']}\\n\"\n                    if book['thumbnail']:\n                        response += f\"![cover]({book['thumbnail']})\\n\"\n                    response += \"\\n\"\n    \n            response += \"\\nðŸ’¬ Use `add [title]` to save â€¢ `reading list` to view\"\n            return response\n# Create the recommender\nrecommender = AIBookRecommender(llm, search_engine, embedding_model)\nprint(\"AI-Powered Book Recommender Ready! ðŸš€\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:30.718885Z","iopub.execute_input":"2025-12-29T18:10:30.719502Z","iopub.status.idle":"2025-12-29T18:10:30.738115Z","shell.execute_reply.started":"2025-12-29T18:10:30.719450Z","shell.execute_reply":"2025-12-29T18:10:30.735939Z"}},"outputs":[{"name":"stdout","text":"AI-Powered Book Recommender Ready! ðŸš€\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Gradio interface","metadata":{}},{"cell_type":"code","source":"with gr.Blocks(theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"#  AI Book Recommender \\n###\")\n    chatbot = gr.Chatbot(height=500, type=\"messages\")  \n    msg = gr.Textbox(placeholder=\"Tell me what you like...\", show_label=False)\n    \n    with gr.Row():\n        submit = gr.Button(\"Send\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    \n    gr.Markdown(\"\"\"\n    ### Try:\n    - \"I want a book like the love hypothesis\"\n    - \"fake dating grumpy sunshine\"\n    - \"dark academia enemies to lovers\"\n    - \"add [book title]\" to save\n    - \"reading list\" to view saved books\n    \"\"\")\n\n    def respond(message, history):\n        if not history: \n            history.append({\"role\": \"assistant\", \"content\": \"Hey! I'm your AI book recommender. Tell me a book you loved or a vibe you're craving! ðŸ“š\"})\n        response = recommender.chat(message, history)\n        history.append({\"role\": \"user\", \"content\": message})\n        history.append({\"role\": \"assistant\", \"content\": response})\n        return \"\", history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n    submit.click(respond, [msg, chatbot], [msg, chatbot])\n    clear.click(lambda: [], None, chatbot) \n    \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:46.322246Z","iopub.execute_input":"2025-12-29T18:10:46.323027Z","iopub.status.idle":"2025-12-29T18:10:46.507935Z","shell.execute_reply.started":"2025-12-29T18:10:46.322993Z","shell.execute_reply":"2025-12-29T18:10:46.507149Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Application Launch","metadata":{}},{"cell_type":"code","source":"demo.queue()\ndemo.launch(share=True, debug=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T18:10:48.017064Z","iopub.execute_input":"2025-12-29T18:10:48.017374Z","iopub.status.idle":"2025-12-29T18:16:13.062032Z","shell.execute_reply.started":"2025-12-29T18:10:48.017343Z","shell.execute_reply":"2025-12-29T18:16:13.061272Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://829f9f0313bf9c83d1.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://829f9f0313bf9c83d1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"Groq status: 200\nSearching for: hey book\nFound 20 unique books\nGroq status: 200\nSearching for: i loved the housemaid what can u suggested? book\nFound 10 unique books\nKeyboard interruption in main thread... closing server.\nKilling tunnel 127.0.0.1:7860 <> https://829f9f0313bf9c83d1.gradio.live\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}