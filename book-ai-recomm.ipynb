{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:12:53.010629Z",
     "iopub.status.busy": "2025-12-30T19:12:53.010243Z",
     "iopub.status.idle": "2025-12-30T19:12:56.738797Z",
     "shell.execute_reply": "2025-12-30T19:12:56.737579Z",
     "shell.execute_reply.started": "2025-12-30T19:12:53.010601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch sentence-transformers gradio requests beautifulsoup4 langchain langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:12:56.741951Z",
     "iopub.status.busy": "2025-12-30T19:12:56.741209Z",
     "iopub.status.idle": "2025-12-30T19:13:00.053319Z",
     "shell.execute_reply": "2025-12-30T19:13:00.052361Z",
     "shell.execute_reply.started": "2025-12-30T19:12:56.741897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:00.054947Z",
     "iopub.status.busy": "2025-12-30T19:13:00.054607Z",
     "iopub.status.idle": "2025-12-30T19:13:03.167623Z",
     "shell.execute_reply": "2025-12-30T19:13:03.166675Z",
     "shell.execute_reply.started": "2025-12-30T19:13:00.054903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.170083Z",
     "iopub.status.busy": "2025-12-30T19:13:03.169826Z",
     "iopub.status.idle": "2025-12-30T19:13:03.175232Z",
     "shell.execute_reply": "2025-12-30T19:13:03.174705Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.170056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.176362Z",
     "iopub.status.busy": "2025-12-30T19:13:03.176107Z",
     "iopub.status.idle": "2025-12-30T19:13:03.195859Z",
     "shell.execute_reply": "2025-12-30T19:13:03.195333Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.176340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OpenSourceLLM:\n",
    "    def __init__(self):\n",
    "        print(\"Real LLM loaded â€” ready to recommend like a human\")\n",
    "        self.api_key = \"\"  # Groq API key\n",
    "        self.api_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        self.model = \"llama-3.3-70b-versatile\"  \n",
    "\n",
    "    def generate(self, prompt, max_tokens=200):\n",
    "        if not self.api_key:\n",
    "            return \"Sweet romance with amazing chemistry and all the feels!\"\n",
    "    \n",
    "        import requests\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.8\n",
    "        }\n",
    "    \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.api_url,\n",
    "                headers={\n",
    "                    \"Authorization\": f\"Bearer {self.api_key.strip()}\",  # Strip any spaces\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                },\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            print(f\"Groq status: {response.status_code}\")  # Debug line\n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            else:\n",
    "                print(f\"Groq error details: {response.text}\")  # Shows exact error\n",
    "                return \"Sweet romance with amazing chemistry and all the feels!\"\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            return \"Sweet romance with amazing chemistry and all the feels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.198067Z",
     "iopub.status.busy": "2025-12-30T19:13:03.197648Z",
     "iopub.status.idle": "2025-12-30T19:13:03.218123Z",
     "shell.execute_reply": "2025-12-30T19:13:03.217408Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.198037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real LLM loaded â€” ready to recommend like a human\n"
     ]
    }
   ],
   "source": [
    "llm = OpenSourceLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.219489Z",
     "iopub.status.busy": "2025-12-30T19:13:03.219105Z",
     "iopub.status.idle": "2025-12-30T19:13:03.238051Z",
     "shell.execute_reply": "2025-12-30T19:13:03.237465Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.219454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BookSearchEngine:\n",
    "    \"\"\"Search books from multiple sources on the web\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.google_books_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "        self.openlibrary_url = \"https://openlibrary.org/search.json\"\n",
    "    \n",
    "    def search_google_books(self, query, max_results=10):\n",
    "        \"\"\"Search Google Books API\"\"\"\n",
    "        try:\n",
    "            params = {\n",
    "                'q': query,\n",
    "                'maxResults': max_results,\n",
    "                'printType': 'books',\n",
    "                'orderBy': 'relevance'\n",
    "            }\n",
    "            response = requests.get(self.google_books_url, params=params, timeout=10)\n",
    "            data = response.json()\n",
    "            \n",
    "            books = []\n",
    "            for item in data.get('items', []):\n",
    "                vol_info = item.get('volumeInfo', {})\n",
    "                books.append({\n",
    "                    'title': vol_info.get('title', 'Unknown'),\n",
    "                    'authors': ', '.join(vol_info.get('authors', ['Unknown'])),\n",
    "                    'description': vol_info.get('description', 'No description available'),\n",
    "                    'categories': ', '.join(vol_info.get('categories', ['General'])),\n",
    "                    'published': vol_info.get('publishedDate', 'N/A'),\n",
    "                    'rating': vol_info.get('averageRating', 'N/A'),\n",
    "                    'thumbnail': vol_info.get('imageLinks', {}).get('thumbnail', ''),\n",
    "                    'source': 'Google Books'\n",
    "                })\n",
    "            return books\n",
    "        except Exception as e:\n",
    "            print(f\"Google Books error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_openlibrary(self, query, max_results=10):\n",
    "        \"\"\"Search Open Library API\"\"\"\n",
    "        try:\n",
    "            params = {\n",
    "                'q': query,\n",
    "                'limit': max_results,\n",
    "                'fields': 'title,author_name,first_publish_year,subject,ratings_average'\n",
    "            }\n",
    "            response = requests.get(self.openlibrary_url, params=params, timeout=10)\n",
    "            data = response.json()\n",
    "            \n",
    "            books = []\n",
    "            for doc in data.get('docs', []):\n",
    "                books.append({\n",
    "                    'title': doc.get('title', 'Unknown'),\n",
    "                    'authors': ', '.join(doc.get('author_name', ['Unknown'])),\n",
    "                    'description': ', '.join(doc.get('subject', ['No description'])[:3]),\n",
    "                    'categories': ', '.join(doc.get('subject', ['General'])[:2]),\n",
    "                    'published': doc.get('first_publish_year', 'N/A'),\n",
    "                    'rating': doc.get('ratings_average', 'N/A'),\n",
    "                    'thumbnail': '',\n",
    "                    'source': 'Open Library'\n",
    "                })\n",
    "            return books\n",
    "        except Exception as e:\n",
    "            print(f\"Open Library error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_books(self, query, max_results=15):\n",
    "        \"\"\"Search books from multiple sources\"\"\"\n",
    "        print(f\"Searching for: {query}\")\n",
    "        \n",
    "        # Search both APIs\n",
    "        google_results = self.search_google_books(query, max_results=max_results//2)\n",
    "        openlibrary_results = self.search_openlibrary(query, max_results=max_results//2)\n",
    "        \n",
    "        # Combine results\n",
    "        all_books = google_results + openlibrary_results\n",
    "        \n",
    "        # Remove duplicates based on title similarity\n",
    "        unique_books = []\n",
    "        seen_titles = set()\n",
    "        for book in all_books:\n",
    "            title_lower = book['title'].lower()\n",
    "            if title_lower not in seen_titles:\n",
    "                seen_titles.add(title_lower)\n",
    "                unique_books.append(book)\n",
    "        \n",
    "        print(f\"Found {len(unique_books)} unique books\")\n",
    "        return unique_books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.239014Z",
     "iopub.status.busy": "2025-12-30T19:13:03.238764Z",
     "iopub.status.idle": "2025-12-30T19:13:03.263229Z",
     "shell.execute_reply": "2025-12-30T19:13:03.262775Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.238985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "search_engine = BookSearchEngine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:03.264317Z",
     "iopub.status.busy": "2025-12-30T19:13:03.264037Z",
     "iopub.status.idle": "2025-12-30T19:13:04.465253Z",
     "shell.execute_reply": "2025-12-30T19:13:04.464519Z",
     "shell.execute_reply.started": "2025-12-30T19:13:03.264287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: science fiction space\n",
      "Found 4 unique books\n",
      "\n",
      "Test search found 4 books:\n",
      "- Deep Space; Eight Stories of Science Fiction by Robert Silverberg\n",
      "- Science Fiction and Space Futures by Eugene Morlock Emme\n",
      "- 2001 by Arthur C. Clarke\n"
     ]
    }
   ],
   "source": [
    "test_results = search_engine.search_books(\"science fiction space\", max_results=5)\n",
    "print(f\"\\nTest search found {len(test_results)} books:\")\n",
    "for book in test_results[:3]:\n",
    "    print(f\"- {book['title']} by {book['authors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:04.467817Z",
     "iopub.status.busy": "2025-12-30T19:13:04.467485Z",
     "iopub.status.idle": "2025-12-30T19:13:05.558306Z",
     "shell.execute_reply": "2025-12-30T19:13:05.557493Z",
     "shell.execute_reply.started": "2025-12-30T19:13:04.467780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Embedding model ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Embedding model ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:05.559698Z",
     "iopub.status.busy": "2025-12-30T19:13:05.559297Z",
     "iopub.status.idle": "2025-12-30T19:13:05.565490Z",
     "shell.execute_reply": "2025-12-30T19:13:05.564679Z",
     "shell.execute_reply.started": "2025-12-30T19:13:05.559659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_book_embeddings(books):\n",
    "    \"\"\"Create embeddings for book search results\"\"\"\n",
    "    if not books:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Create rich text for embedding\n",
    "    texts = []\n",
    "    for book in books:\n",
    "        text = f\"{book['title']}. {book['description']} {book['categories']}\"\n",
    "        texts.append(text)\n",
    "    \n",
    "    embeddings = embedding_model.encode(texts)\n",
    "    return embeddings\n",
    "\n",
    "def semantic_rerank(books, query, top_k=5):\n",
    "    \"\"\"Rerank books using semantic similarity\"\"\"\n",
    "    if not books:\n",
    "        return []\n",
    "    \n",
    "    book_embeddings = create_book_embeddings(books)\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    \n",
    "    similarities = cosine_similarity(query_embedding, book_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    ranked_books = [books[i] for i in top_indices]\n",
    "    return ranked_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:05.566869Z",
     "iopub.status.busy": "2025-12-30T19:13:05.566480Z",
     "iopub.status.idle": "2025-12-30T19:13:05.598938Z",
     "shell.execute_reply": "2025-12-30T19:13:05.598260Z",
     "shell.execute_reply.started": "2025-12-30T19:13:05.566841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI-Powered Book Recommender Ready! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "class AIBookRecommender:\n",
    "    def __init__(self, llm, search_engine, embedding_model):\n",
    "        self.llm = llm\n",
    "        self.search_engine = search_engine\n",
    "        self.embedding_model = embedding_model\n",
    "        self.reading_list = []\n",
    "        self.last_search_results = []\n",
    "        self.last_embeddings = None\n",
    "\n",
    "    def create_book_embeddings(self, books):\n",
    "        \"\"\"Create embeddings for book search results\"\"\"\n",
    "        if not books:\n",
    "            return np.array([])\n",
    "        \n",
    "        texts = []\n",
    "        for book in books:\n",
    "            text = f\"{book['title']}. {book['description']} {book['categories']}\"\n",
    "            texts.append(text)\n",
    "        \n",
    "        embeddings = self.embedding_model.encode(texts)\n",
    "        return embeddings\n",
    "\n",
    "    def semantic_rerank(self, books, query, top_k=20):\n",
    "        \"\"\"Rerank books using semantic similarity\"\"\"\n",
    "        if not books:\n",
    "            return []\n",
    "        \n",
    "        book_embeddings = self.create_book_embeddings(books)\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        \n",
    "        similarities = cosine_similarity(query_embedding, book_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        ranked_books = [books[i] for i in top_indices]\n",
    "        return ranked_books\n",
    "\n",
    "    def extract_intent(self, user_message):\n",
    "        \"\"\"Extract book title and tropes using LLM + fallbacks, then build smart search query\"\"\"\n",
    "        lower = user_message.lower()\n",
    "\n",
    "        # If no \"like\" or genre keywords â†’ just search for the message + \"books\"\n",
    "        if not any(phrase in lower for phrase in [\"like\", \"similar\", \"recommend\", \"loved\", \"read\", \"want\", \"something\"]):\n",
    "            return user_message + \" books\", None\n",
    "\n",
    "        # LLM prompt to extract structured intent\n",
    "        intent_prompt = f\"\"\"\n",
    "User message: \"{user_message}\"\n",
    "\n",
    "Extract:\n",
    "1. The exact book title they want something similar to (if mentioned). Return \"None\" if not clear.\n",
    "2. List of key tropes, genres, or vibes they mentioned or implied (e.g. fake dating, enemies to lovers, dark academia, cozy fantasy, slow burn, found family).\n",
    "\n",
    "Format exactly as:\n",
    "BOOK: <title or None>\n",
    "TROPES: trope1, trope2, trope3\n",
    "\n",
    "Only respond with those two lines.\n",
    "\"\"\"\n",
    "\n",
    "        response = self.llm.generate(intent_prompt, max_tokens=100).strip()\n",
    "\n",
    "        # Parse LLM response\n",
    "        book_title = None\n",
    "        tropes = []\n",
    "        for line in response.split('\\n'):\n",
    "            if line.startswith(\"BOOK:\"):\n",
    "                title = line[5:].strip()\n",
    "                if title.lower() != \"none\":\n",
    "                    book_title = title\n",
    "            elif line.startswith(\"TROPES:\"):\n",
    "                trope_str = line[7:].strip()\n",
    "                if trope_str:\n",
    "                    tropes = [t.strip() for t in trope_str.split(',') if t.strip()]\n",
    "\n",
    "        # Fallback: regex for book title\n",
    "        if not book_title:\n",
    "            import re\n",
    "            match = re.search(r\"(?:like|similar to|loved|read|something like)\\s+([a-zA-Z0-9\\s,'\\\"\\-\\.&!]+?)(?:\\s+by|\\?|$|,)\", lower)\n",
    "            if match:\n",
    "                book_title = match.group(1).strip().title()\n",
    "\n",
    "        # Fallback: keyword trope detection\n",
    "        if not tropes:\n",
    "            common_checks = {\n",
    "                'fake dating': ['fake dat', 'fake relat', 'pretend', 'fake boyfriend', 'fake girlfriend'],\n",
    "                'friends to lovers': ['friend', 'best friend', 'childhood friend', 'friends to lovers'],\n",
    "                'enemies to lovers': ['enem', 'hate to love', 'rival'],\n",
    "                'grumpy sunshine': ['grumpy', 'sunshine'],\n",
    "                'slow burn': ['slow burn', 'slowburn'],\n",
    "                'romcom': ['romcom', 'romantic comedy', 'funny romance'],\n",
    "                'young adult': ['ya', 'young adult', 'teen'],\n",
    "                'new adult': ['new adult', 'college'],\n",
    "                'dark academia': ['dark academia', 'academic'],\n",
    "                'cozy fantasy': ['cozy', 'wholesome fantasy'],\n",
    "                'closed door': ['clean', 'closed door', 'no spice', 'sweet'],\n",
    "            }\n",
    "            for trope, keywords in common_checks.items():\n",
    "                if any(k in lower for k in keywords):\n",
    "                    tropes.append(trope)\n",
    "\n",
    "        # Build powerful search query\n",
    "        parts = []\n",
    "        if book_title:\n",
    "            parts.append(f'\"{book_title}\"')\n",
    "            parts.append(\"similar books\")\n",
    "            parts.append(\"read alikes\")\n",
    "            parts.append(\"goodreads recommendations\")\n",
    "            parts.append(\"booktok recommendations\")\n",
    "        else:\n",
    "            parts.append(\"books\")\n",
    "\n",
    "        if tropes:\n",
    "            parts.extend(tropes)\n",
    "\n",
    "        if \"book\" not in \" \".join(parts).lower():\n",
    "            parts.append(\"book\")\n",
    "\n",
    "        query = \" \".join(parts)\n",
    "        return query, book_title\n",
    "\n",
    "    def chat(self, user_message, history=[]):\n",
    "        user_message_lower = user_message.lower().strip()\n",
    "    \n",
    "        # Commands\n",
    "        if user_message_lower.startswith(\"add \"):\n",
    "            # your existing add logic\n",
    "            pass\n",
    "        elif user_message_lower in [\"reading list\", \"my list\"]:\n",
    "            # your existing reading list logic\n",
    "            pass\n",
    "        else:\n",
    "            # FULL LLM MODE â€” this is the magic\n",
    "            prompt = f\"\"\"\n",
    "    You are the world's best book recommender in 2025. You know every BookTok trend, Goodreads list, and reader preference.\n",
    "    \n",
    "    User wants: \"{user_message}\"\n",
    "    \n",
    "    Recommend exactly 5 books that REAL readers say are the closest matches.\n",
    "    Rules:\n",
    "    - If a specific book is mentioned â†’ prioritize same author + exact trope matches\n",
    "    - Always respect age group: YA for teens, adult for mature\n",
    "    - Use current trends: BookTok hits, popular 2024-2025 releases\n",
    "    - No children's books, textbooks, or random classics unless asked\n",
    "    \n",
    "    Format:\n",
    "    1. \"Title\" by Author\n",
    "       â†’ One sharp sentence why it's perfect\n",
    "    \n",
    "    Examples:\n",
    "    \"betting on you\" â†’ Lynn Painter books first (Better Than the Movies, The Do-Over, etc.)\n",
    "    \"the housemaid\" â†’ Freida McFadden thrillers (Never Lie, The Teacher, etc.)\n",
    "    \"love hypothesis\" â†’ Ali Hazelwood + Spanish Love Deception\n",
    "    \"\"\"\n",
    "    \n",
    "            recommendations = self.llm.generate(prompt, max_tokens=500).strip()\n",
    "    \n",
    "            # Optional: Fetch covers for visual polish (doesn't affect quality)\n",
    "            try:\n",
    "                cover_books = self.search_engine.search_books(user_message + \" book\", max_results=20)\n",
    "                ranked = self.semantic_rerank(cover_books, user_message, top_k=5)\n",
    "                self.last_search_results = ranked\n",
    "            except:\n",
    "                self.last_search_results = []\n",
    "    \n",
    "            response = f\"ðŸ“š **Perfect matches for: \\\"{user_message}\\\"**\\n\\n\"\n",
    "            response += recommendations + \"\\n\\n\"\n",
    "            if self.last_search_results:\n",
    "                response += \"ðŸ“– **With covers:**\\n\\n\"\n",
    "                for book in self.last_search_results[:3]:\n",
    "                    response += f\"**{book['title']}** by {book['authors']}\\n\"\n",
    "                    if book['thumbnail']:\n",
    "                        response += f\"![cover]({book['thumbnail']})\\n\"\n",
    "                    response += \"\\n\"\n",
    "    \n",
    "            response += \"\\nðŸ’¬ Use `add [title]` to save â€¢ `reading list` to view\"\n",
    "            return response\n",
    "# Create the recommender\n",
    "recommender = AIBookRecommender(llm, search_engine, embedding_model)\n",
    "print(\"AI-Powered Book Recommender Ready! ðŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:05.600348Z",
     "iopub.status.busy": "2025-12-30T19:13:05.599890Z",
     "iopub.status.idle": "2025-12-30T19:13:05.788946Z",
     "shell.execute_reply": "2025-12-30T19:13:05.788198Z",
     "shell.execute_reply.started": "2025-12-30T19:13:05.600313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"#  AI Book Recommender \\n###\")\n",
    "    chatbot = gr.Chatbot(height=500, type=\"messages\")  \n",
    "    msg = gr.Textbox(placeholder=\"Tell me what you like...\", show_label=False)\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit = gr.Button(\"Send\", variant=\"primary\")\n",
    "        clear = gr.Button(\"Clear\")\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ### Try:\n",
    "    - \"I want a book like the love hypothesis\"\n",
    "    - \"fake dating grumpy sunshine\"\n",
    "    - \"dark academia enemies to lovers\"\n",
    "    - \"add [book title]\" to save\n",
    "    - \"reading list\" to view saved books\n",
    "    \"\"\")\n",
    "\n",
    "    def respond(message, history):\n",
    "        if not history: \n",
    "            history.append({\"role\": \"assistant\", \"content\": \"Hey! I'm your AI book recommender. Tell me a book you loved or a vibe you're craving! ðŸ“š\"})\n",
    "        response = recommender.chat(message, history)\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "        history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return \"\", history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: [], None, chatbot) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:13:05.790400Z",
     "iopub.status.busy": "2025-12-30T19:13:05.789832Z",
     "iopub.status.idle": "2025-12-30T19:15:42.738428Z",
     "shell.execute_reply": "2025-12-30T19:15:42.737653Z",
     "shell.execute_reply.started": "2025-12-30T19:13:05.790367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://e6b6a60a4f9b4c1742.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e6b6a60a4f9b4c1742.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq status: 200\n",
      "Searching for: can you suggest something like the housemaid book\n",
      "Found 10 unique books\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://e6b6a60a4f9b4c1742.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.queue()\n",
    "demo.launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
